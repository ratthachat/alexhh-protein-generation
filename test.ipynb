{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 07:59:34.822204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-18 07:59:34.822260: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# from models.vaes import MSAVAE\n",
    "from models.protcnn import ProtMSAVAE\n",
    "from utils.io import load_gzdata\n",
    "from utils.data_loaders import one_hot_generator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, raw_seqs = load_gzdata('data/training_data/ll_train.fa.gz', one_hot=False)\n",
    "b, msa_seqs = load_gzdata('data/training_data/luxafilt_llmsa_train.fa.gz', one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(raw_seqs), len(msa_seqs)\n",
    "# print(raw_seqs[:5])\n",
    "# lraw = np.array([len(s) for s in raw_seqs])\n",
    "# print(lraw.mean(), lraw.std(), lraw.max(), lraw.min())\n",
    "\n",
    "# print(msa_seqs[0])\n",
    "# print(msa_seqs[1])\n",
    "# print(msa_seqs[-1])\n",
    "# lmsa = np.array([len(s) for s in msa_seqs])\n",
    "# print(lmsa.mean(), lmsa.std(), lmsa.max(), lmsa.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 360, 21) (32, 360, 21)\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "train_gen = one_hot_generator(msa_seqs, padding=None)\n",
    "for (x,y) in train_gen:\n",
    "    print(x.shape, y.shape)\n",
    "    print(x[0, 0,:], y[0, 0,:])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate  0.001\n",
      "Protein VAE initialized !\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 360, 21)]    0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             [(None, 10),         2006548     ['input_3[0][0]']                \n",
      "                                 (None, 10)]                                                      \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 10)           0           ['model[0][0]',                  \n",
      "                                                                  'model[0][1]']                  \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 360, 21)      2011528     ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,018,076\n",
      "Trainable params: 4,018,076\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 07:59:38.711552: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-18 07:59:38.711596: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-18 07:59:38.711623: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (codespaces-3a659a): /proc/driver/nvidia/version does not exist\n",
      "2022-05-18 07:59:38.711838: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = ProtMSAVAE()\n",
    "model.VAE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 2s 30ms/step - loss: 732.8474 - accuracy: 0.4806 - aa_acc: 0.1910 - xent_loss: 733.3474 - kl_loss: -0.5000 - vae_loss: 732.8474\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 539.3777 - accuracy: 0.5631 - aa_acc: 0.2140 - xent_loss: 539.8777 - kl_loss: -0.5000 - vae_loss: 539.3777\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 520.4052 - accuracy: 0.5738 - aa_acc: 0.2265 - xent_loss: 520.9052 - kl_loss: -0.5000 - vae_loss: 520.4052\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 466.7695 - accuracy: 0.6192 - aa_acc: 0.3107 - xent_loss: 467.2695 - kl_loss: -0.5000 - vae_loss: 466.7695\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 418.1354 - accuracy: 0.6620 - aa_acc: 0.3825 - xent_loss: 418.6354 - kl_loss: -0.5000 - vae_loss: 418.1354\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 374.4152 - accuracy: 0.6910 - aa_acc: 0.4362 - xent_loss: 374.9152 - kl_loss: -0.5000 - vae_loss: 374.4152\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 360.8103 - accuracy: 0.7037 - aa_acc: 0.4556 - xent_loss: 361.3103 - kl_loss: -0.5000 - vae_loss: 360.8103\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 331.6686 - accuracy: 0.7243 - aa_acc: 0.4860 - xent_loss: 332.1686 - kl_loss: -0.5000 - vae_loss: 331.6686\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 317.0398 - accuracy: 0.7335 - aa_acc: 0.5039 - xent_loss: 317.5398 - kl_loss: -0.5000 - vae_loss: 317.0398\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 316.7299 - accuracy: 0.7333 - aa_acc: 0.5040 - xent_loss: 317.2299 - kl_loss: -0.5000 - vae_loss: 316.7299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa48eda8130>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.VAE.fit(train_gen, epochs=10, steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "['MKFSLFTHGVSHEQRFEELVELAELADALGFDAVWIGEHHGMEFPSPEVLLAALAARTKRIRLGTGTVVAPHPIRLAEECALLDHLSNGRLELGLGRGAVDYDRLGLDESRQLMRENYDLLRRLWRGDVTWDGEFFKFPTVVPKPLQGPPIWVARSPESAEFAAARGLNVMVTNLGLEVALVNLYREALAGHPPMLRHTHVADDREDAKVAAKYTFDNWFQVELEELRANLIIGTPEEVIEKILYYQEAGDESLGEKKKSLELFAEEVMPAFRETA', 'MKFSLFVHMESHRQRFEELVELAELADALGFDAVWIGEHHGMEFISPSPLTLLAYLAARTKRIRLGTGTVVAPHPVRLAEECALLDHLSNGRLELGLGRGAYYDRLGLDESGQLMRENYPALRRLWRGVSHDGEFFKFPTTSVPKPLQGPPVWVARSPESHEFAAANGCGVLVTNLPLEEVALVNKYREAFAGHPPQIMLRHTYVADDREDAKVARKYFDNWFNKELEELRRNGAMIGTPEEVIERILYYEALGDEFSLGEKKKSLELFAEEVVPFRA', 'MKFSLFTHGSHTQRFEELVELAELADALGFDAVWIGEHHGMEFPSPTTLLAYLAARTKRIRLGTGTVVAPHPVRLAEEYALLDHLSNGRLELGLGRGAVYDRLGLDESGQLMRENYPLLRRLWRGVSHDGEFFRFPTSVPKPLQGPPVWVARSPESAEFAAANGLGVLVTNLPLEEVALVNLYREAFAGHPPQIMLRHTYVADDREDAKVARKYFDNWFELELRRNGAMIGTPEEVIEKILYYEAGDESLGEKKKSLELFAEEVVPFRA', 'MKFSLFTHGESHEQRFEELVELAELADALGFDAVWIGEHHGMEFISPSPTTLLAYLAARTKRIRLGTGTTVAPHPVRLAEEYALLDHLSNGRLELGLGRGAVYDRLGLDESGQLMRENYPLLRRLWRGDVDHDGEFFRFPTTSVPKPLQGPPVWHARSPESAEFAAANGLGVLVTNLPLEEVALVNLYREAFAGHPPQIMLRHTYVADDNEDAKVARKYFDNWFELEELRRNTAMIGTPEEVIEKILYYEAGYDESLGEKKKSLELFAEEVVPAFRAAR', 'MKFSLFTHMESHEQRFEELVELAELADALGFDAVWIGEHHGMEFISPSPTTLLAYLAARTKRIRLGTGTVVAPHPVRLAEEYALLDHLSNGRLELGLGRGAVYDRLGLDESGQLMRENYPLLRRLWRGDVDHDGEFFRFPTTSVPRPLQGPPVWHARSPESAEFAAANGCGVLVTNLPLEEVALVNLYREAFAGHPPQIMLRHTYVADDNEDAKVARKYFDNWFELEELRRNGTMIGTPEEVIEKILYYEAGYDESLGEKKKSLELFAEEVVPAFREAAR']\n"
     ]
    }
   ],
   "source": [
    "xx = model.generate_variants_luxA(5)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "['MKFSLFTHG------SHTERFEELVELAELADALGFDAVWIGEHHGMEF---PSPTVLLAYLAARTKRIRLGTGTVVAP--HPVRLAEEYALLDHLSNGR-ELGLGRGA--V-YDRLGLD--ESGQLMRENYPLLRRLWRE--VDHDGEFFRFP-T-SVPRPLQ--GPPVWHAR-SPESAEFAAANGLGVLVTNL-PLEEVA-LVNLYREAFA--GHP-PQIM--L-RHTYVADDREDA-KVARPY-------FDNWF-----------------------------EL--ELERNG-TMIGTPEEVIEKILYY-EA-G-DE-SL----G----EKKKSLELFAEEVVP-FR-ETAA-R-', 'MKFSLFTHG------SHEQRFEELVELAELADALGFDAVWIGEHHGMEF---PSPTVLLAYLAARTKRIRLGTGTTVAP--HPVRLAEEYALLDHLSNGR-ELGLGRGA--V-YDRLGLD--ESRQLMRENYDLLRRLWRE--VTWDGEFFRFP-T-SVPRPLQ--GPPVWHAA-S-ESAEFAAARGLGVLVTNL-PLEEVA-LVNLYREAFA--GHD-PQIM--L-RHTYVADDNEDA-KRARPY-------FDNW------------------------------E---ELEANG-TIIGTPEEVIEKILYY-EA-G-DE-SL----G----EKKKSLELFAEEVVPAFR-ETAA-R-', 'MKFSLFTHG------SHEQRFEELVELAELADALGFDAVWIGEHHGMEF---PSPEVLLAALAARTKRIRLGTGTVVAP--HPVRLAEEYALLDHLSNGRLELGLGRGA--V-YDRLGLD--ESRQLMRENYDLLRRLWRG--VSHDGEFFKFP---SVPKPLQ--GPPIWVAR-SPESAEFAAANGLNVLVTNL-PLEEVA-LVNLYREAFA--GHP-PQIM--L-RHTYVADDREDA-KVARKY-------FDNWF-----------------------------EL--ELRANG-LIIGTPEEVIEKILYY-EA-G-DE-SL----G----EKKKSLELFAEEVMPAFR-ETA----', 'MKFSLFTHG------SHTQRFEELVELAELADALGFDAVWIGEHHGMEF---PSPEVLLAALAARTKRIRLGTGTVVAP--HPVRLAEEYALLDHLSNGR-ELGLGRGA--V-YDRLGLD--ESRQLMRENYDLLRRLWRG--VTHDGEFFRFP---SVPRPLQ--GPPIWVAR-S-ESAEFAAARGLNVLVTNL-PLEEVA-LVNLYREAFA--GHP-PQIM--L-RHTYVADDREDA-KVARKY-------FDNWF----V------------------------EL--ELRANG-LIIGTPEEVIEKILYY-EA-G-DE-SL----G----EKKKSLELFAEEVMP-FR-ETA----', 'MKFSLFTHME-----SHTQRFEELVELAELADALGFDAVWIGEHHGMEF-ISPSPTTLLAYLAARTKRIRLGTGTVVAP--HPVRLAEEYALLDHLSNGRLELGLGRGA--V-YDRLGLD--ESGQLMRENYPLLRRLWRG--VSHDGEFFRFP-TTSVPKPLQ--GPPVWVAR-SPESAEFAAANGLGVLVTNL-PLEEVA-LVNLYREAFA--GHP-PQIM--L-RHTYVADDREDA-KVARKY-------FDNWF-N---------------------------EL-EELRRNG-LMIGTPEEVIEKILYY-EALG-DE-SL----G----EKKKSLELFAEEVVP-FR---A----']\n"
     ]
    }
   ],
   "source": [
    "xx = model.generate_variants_luxA(5,remove_gaps=False)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewrite the VAE using keras subclass module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from models.encoders import fc_encoder\n",
    "from models.decoders import fc_decoder\n",
    "\n",
    "encoder_kwargs={'encoder_hidden': [256, 256],\n",
    "                        'encoder_dropout': [0., 0.]}\n",
    "decoder_kwargs={'decoder_hidden': [256,256],\n",
    "                        'decoder_dropout': [0.,0.]}\n",
    "activation='relu'\n",
    "alphabet_size=21\n",
    "original_dim=360\n",
    "latent_dim=10\n",
    "\n",
    "E = fc_encoder(original_dim, latent_dim,\n",
    "                            n_conditions=0,\n",
    "                            alphabet_size=alphabet_size,\n",
    "                            activation=activation,\n",
    "                            **encoder_kwargs)\n",
    "G = fc_decoder(latent_dim, original_dim,\n",
    "                            n_conditions=0,\n",
    "                            alphabet_size=alphabet_size,\n",
    "                            activation=activation,\n",
    "                            **decoder_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loaders import right_pad, to_one_hot\n",
    "from utils import aa_letters, luxa_seq\n",
    "from utils.decoding import _decode_nonar\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        data=data[0] # since alexhh's train_gen return (data, data)\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var = self.encoder(data)\n",
    "            z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1) # Fix dimension from Keras' example\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "        \n",
    "    def prior_sample(self, n_samples=1, mean=0, stddev=1,\n",
    "                     remove_gaps=False, batch_size=5000):\n",
    "        if n_samples > batch_size:\n",
    "            x = []\n",
    "            total = 0\n",
    "            while total< n_samples:\n",
    "                this_batch = min(batch_size, n_samples - total)\n",
    "                z_sample = mean + stddev * np.random.randn(this_batch, self.latent_dim)\n",
    "                x += self.decode(z_sample, remove_gaps=remove_gaps)\n",
    "                total += this_batch\n",
    "        else:\n",
    "            z_sample = mean + stddev * np.random.randn(n_samples, self.latent_dim)\n",
    "            x = self.decode(z_sample, remove_gaps=remove_gaps)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, remove_gaps=False, sample_func=None, conditions=None):\n",
    "        return _decode_nonar(self.decoder, z, remove_gaps=remove_gaps, conditions=conditions)\n",
    "\n",
    "    def generate_variants_luxA(self, num_samples, posterior_var_scale=1., temperature=0.,\n",
    "                               solubility_level=None,remove_gaps=True):\n",
    "\n",
    "        luxa_oh = to_one_hot(right_pad([luxa_seq], self.encoder.input_shape[1]))\n",
    "        luxa_oh = np.repeat(luxa_oh, num_samples, axis=0)\n",
    "        orig_conds = np.repeat(np.array([1,0,0]).reshape((1,3)), num_samples, axis=0)\n",
    "        inputs = luxa_oh if solubility_level is None else [luxa_oh, orig_conds]\n",
    "\n",
    "        # luxa_zmean, luxa_zvar, luxa_z = self.stochastic_E.predict(inputs)\n",
    "        z_mean, z_log_var = self.encoder(inputs)\n",
    "        luxa_z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "        print(luxa_z.shape)\n",
    "\n",
    "        # if posterior_var_scale != 1.:\n",
    "        #     luxa_z = np.sqrt(posterior_scale*luxa_zvar)*np.random.randn(*luxa_zmean.shape) + luxa_zmean\n",
    "\n",
    "        sample_func = None\n",
    "        if temperature > 0:\n",
    "            sample_func = partial(batch_temp_sample, temperature=temperature)\n",
    "        target_conds = None if solubility_level is None else luxa_batch_conds(num_samples, solubility_level)\n",
    "        return self.decode(luxa_z, remove_gaps=remove_gaps, sample_func=sample_func,\n",
    "                           conditions=target_conds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 1s 22ms/step - loss: 33.7548 - reconstruction_loss: 30.3343 - kl_loss: 3.0394\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 33.2902 - reconstruction_loss: 30.9973 - kl_loss: 2.7631\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 32.0498 - reconstruction_loss: 30.1041 - kl_loss: 2.8632\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 33.5730 - reconstruction_loss: 30.3717 - kl_loss: 2.7335\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 33.7521 - reconstruction_loss: 30.7133 - kl_loss: 2.8908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3c3d05780>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(E, G)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "\n",
    "vae.fit(train_gen, epochs=5,  steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "['MRFGLF-----------PD----LLELARAAEELGFDSAWVAEHHFA-----PDPLVLLAALAARTSRIRLGTGVLVLP--HPLLLAKQAATLDLLS-GR--LGVG-G----E--A-------RGARLDEALEVLRALWTG----FEG-----------P-P--P-RPPIWVGG----ALR-AARHGDGWLSS-------L--LIAAYREAA--------------------------A--------------------------------------------------------------GTPDEVADRL---------D-------------------E-FA---LP-L---------', 'MEFGLF--G--------AERLRELVELAVLAEELGFDVFWVGEHHF------SSPFVLLAAAAARTKRIRLGTGVTVLP--DPVRVAEDFATLDHLS-GR-ELGVGRG----EFPLF-YD---YRELFEEKLELLRRLWRG--VTWEGE-F------VYPRP-Q--GPPIWVGGG--ESAERAARLGDGLMSAT--P--RLA-LIDLYREAAA--GHD----------HVFVAD-D--A-A--RYY-------F---------------------------------------F-------G-P-EVIEKLL-LREA---DR--------------LRSIE-FAEEVAP-LR--------', 'MRFGLF-----------PD----LLELARAAEELGFDSAWVREHHFA-----PDPFVLLAAAAARTSRIRLGTGVLVLP--HPLLLAKEAATLDLLS-GR-ELGVG-G----E--A-------RGARLREALEALRALWTG----FDG-F---------PKP-QP-RPPIWVGG----ALRWAARHGDGWLSSG------L--LIEAYREAA--------------------------A--------------------------------------------------------------GTPDEVIDRL---------D-------------------E-FA--VLP-L---------', 'MRFGLF-----------PD----LLELARAAEELGFDSAWVREHHFA-----PDPFVLLAAAAARTSRIRLGTGVLVLP--HPLRLAKEAATLDLLS-GR--LGVG-G----E--A-------RGARLDEALEVLRALWTG----FEG-----------P-P-QP-RPPIWVGG----ALRWAARHGDGWLSS-------L--LIEAYREAA--------------------------A--------------------------------------------------------------GTPDEVIERL---------D-------------------E-FA--VLP-L---------', 'MKFGLF-----------ADALE-LLELAVLAEELGFDAAWVGEHHFA-----PSPFVLLAAAAARTSRIRLGTGVIVLP--HPLRLAEDAATLDLLS-GR-ELGVGRG----EF-AF------RRERFDEFLELLRRLWTG---A-EGEF-------L-PKP-QP-GPPIWVGGS---SARWAARNGDGLLSSPL-----LA-LIEAYREAAA--G---------------VAD-D--A-A-----------------------------------------------------------IGTPDEVIERL-R---A---DE--------------LRSLE-FAEEVAP-FR--------']\n"
     ]
    }
   ],
   "source": [
    "xx = vae.generate_variants_luxA(5,remove_gaps=False)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "['MRFGLFADALLELAVLAEELGFDSAWVGEHHFPSPFVLLAAAAARTSRIRLGTGVIVLPHPLRLAEDAATLDLLSGRELGVGRGEAFRRARFREALEVLRRLWTGFEGEPRPQRPPIWVGGSARRAARHGDGLLSSGLLIEAYREAAGAAGPDEVIERLDESLEFAEVAPLR', 'MRFGLFPDLLELAVAAEELGFDSAWVREHHFAPSPFVLLAAAAARTSRIRLGTGVIVLPHPLRLAKEAATLDLLSGRELGVGGEARGARLREALEALRALWTGFEGEFPKPQPRPPIWVGGSLRWAARHGDGWLSSGLLLIEAYREAAGAGTPDEVIDRLDTSLEFAEVAPL', 'MRFGLFPDLLELARAAEELGFDSAWVADHLFPDPFVLLAALATRIRLGTGVLLHPAVLAKQAATLDHLSGRLGVGAGWERGARLREALEVLRALWTFGYPPPPIWVGGALRAARHADGWLLLAALRAGPDELARLAP', 'MRFGLFPDLLELARAAEELGFDSAWVSDHLPDPWVLLAALARIRLGTGVLPHPAVLAKQAATLDHLSGRLGVGAGERLARLREALEILRALWTFDGYPPPIWVAGALRAARHADGWLIAALRAGDELRLDAP', 'MRFGLFPDLLELARAAEELGFDSAWVSDHLFPDPWVTLAALARTRIRLGTGVLLHPAVLAKAAATLDQLSGRLGVGAGWERGARLREALEIIRALWTFDGEYPKPRPILVGGTLRAARHADGWLLLAALRAAGRGSPDELALAP']\n"
     ]
    }
   ],
   "source": [
    "xx = vae.generate_variants_luxA(5,remove_gaps=True)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f946df053fbf2b937619d3c5458e7af74262f9a954d8797ba0b27400bcafe06"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
